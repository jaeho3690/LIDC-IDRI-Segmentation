{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jaeho_ubuntu/Lung/notebook'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(output, target):\n",
    "    smooth = 1e-5\n",
    "    \n",
    "    output = output.view(-1).data.cpu().numpy()\n",
    "    target = target.view(-1).data.cpu().numpy()\n",
    "    intersection = (output * target).sum()\n",
    "    \n",
    "\n",
    "    return (2. * intersection + smooth) / \\\n",
    "        (output.sum() + target.sum() + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_iou(output,target):\n",
    "    smooth = 1e-5\n",
    "    output = output.view(-1).data.cpu().numpy()\n",
    "    target = target.view(-1).data.cpu().numpy()\n",
    "    intersection = (output * target).sum()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(output, target):\n",
    "    smooth = 1e-5\n",
    "\n",
    "    if torch.is_tensor(output):\n",
    "        output = output.data.cpu().numpy()\n",
    "    if torch.is_tensor(target):\n",
    "        target = target.data.cpu().numpy()\n",
    "    output_ = output > 0.5\n",
    "    target_ = target > 0.5\n",
    "    intersection = (output_ & target_).sum()\n",
    "    union = (output_ | target_).sum()\n",
    "\n",
    "    return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dir = '/home/LUNG_DATA/Unet_output_data/UNET_with_Augmenetation/'\n",
    "actual_mask_dir = '/home/LUNG_DATA/Mask_1/LIDC-IDRI-0001/0001_MA000_slice004.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.load(prediction_dir+'0001_nodule0_slice04_predict.npy')\n",
    "mask = np.load(actual_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = torch.tensor(prediction)\n",
    "mask = torch.tensor(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ = predict.view(predict.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(prediction >0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Subtraction, the `-` operator, with two bool tensors is not supported. Use the `^` or `logical_xor()` operator instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b49498f7c81d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2124\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Subtraction, the `-` operator, with two bool tensors is not supported. Use the `^` or `logical_xor()` operator instead."
     ]
    }
   ],
   "source": [
    "F.binary_cross_entropy_with_logits(predict, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_img(prediction, mask):\n",
    "    fig,ax = plt.subplots(1,2, figsize=(15,15))\n",
    "    ax[0].title.set_text('Original Mask')\n",
    "    ax[0].imshow(mask)\n",
    "    ax[0].grid()\n",
    "    ax[1].title.set_text('Prediction Mask')\n",
    "    ax[1].imshow(mask)\n",
    "    ax[1].grid()\n",
    "    plt.show()\n",
    "    predict = torch.tensor(prediction)\n",
    "    mask = torch.tensor(mask)\n",
    "    print(\"DICE COEFFICIENT IS\",dice_coef(predict,mask))\n",
    "    print(\"IOU IS\",iou_score(predict,mask) )\n",
    "    print(\"BCE LOSS IS\",F.binary_cross_entropy_with_logits(prediction, mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICE COEFFICIENT IS 0.9150244435852068\n",
      "IOU IS 0.8832997999668029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Subtraction, the `-` operator, with two bool tensors is not supported. Use the `^` or `logical_xor()` operator instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-fc2c7739a62a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mview_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-a18685c6469f>\u001b[0m in \u001b[0;36mview_img\u001b[0;34m(prediction, mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DICE COEFFICIENT IS\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdice_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IOU IS\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miou_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BCE LOSS IS\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2124\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Subtraction, the `-` operator, with two bool tensors is not supported. Use the `^` or `logical_xor()` operator instead."
     ]
    }
   ],
   "source": [
    "view_img(predict, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from '/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1020.2257)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.6396e-05, 7.6686e-05, 7.1254e-05,  ..., 7.4787e-05, 9.4663e-05,\n",
       "         6.3159e-05],\n",
       "        [7.8946e-05, 8.1808e-05, 7.7624e-05,  ..., 7.7501e-05, 9.9823e-05,\n",
       "         4.8354e-05],\n",
       "        [7.5250e-05, 8.2277e-05, 8.0477e-05,  ..., 7.2782e-05, 9.2923e-05,\n",
       "         4.5505e-05],\n",
       "        ...,\n",
       "        [6.5591e-05, 6.6887e-05, 5.8088e-05,  ..., 1.2479e-04, 1.0186e-04,\n",
       "         1.5028e-04],\n",
       "        [8.5441e-05, 9.6792e-05, 8.6790e-05,  ..., 1.0744e-04, 9.2301e-05,\n",
       "         1.5220e-04],\n",
       "        [5.8959e-05, 5.0072e-05, 5.0726e-05,  ..., 1.3233e-04, 1.3239e-04,\n",
       "         1.6712e-04]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.6084e+05, 8.7000e+01, 4.0000e+01, 2.7000e+01, 1.0000e+01, 1.4000e+01,\n",
       "        9.0000e+00, 5.0000e+00, 5.0000e+00, 1.0000e+01, 8.0000e+00, 1.0000e+01,\n",
       "        6.0000e+00, 1.0000e+00, 8.0000e+00, 3.0000e+00, 1.0000e+00, 2.0000e+00,\n",
       "        4.0000e+00, 2.0000e+00, 2.0000e+00, 5.0000e+00, 5.0000e+00, 3.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 5.0000e+00, 2.0000e+00, 1.0000e+00, 6.0000e+00,\n",
       "        3.0000e+00, 2.0000e+00, 2.0000e+00, 2.0000e+00, 2.0000e+00, 1.0000e+00,\n",
       "        2.0000e+00, 1.0000e+00, 5.0000e+00, 3.0000e+00, 4.0000e+00, 1.0000e+00,\n",
       "        2.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 3.0000e+00, 2.0000e+00,\n",
       "        2.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00, 2.0000e+00, 2.0000e+00,\n",
       "        0.0000e+00, 2.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.0000e+00, 1.0000e+00, 5.0000e+00, 3.0000e+00, 1.0000e+00, 2.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 2.0000e+00, 5.0000e+00,\n",
       "        2.0000e+00, 2.0000e+00, 1.0000e+00, 3.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "        2.0000e+00, 1.0000e+00, 3.0000e+00, 3.0000e+00, 6.0000e+00, 5.0000e+00,\n",
       "        0.0000e+00, 4.0000e+00, 2.0000e+00, 3.0000e+00, 3.0000e+00, 5.0000e+00,\n",
       "        9.0000e+00, 1.0000e+00, 1.3000e+01, 6.0000e+00, 1.5000e+01, 8.0000e+00,\n",
       "        1.2000e+01, 2.3000e+01, 3.7000e+01, 7.7600e+02])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.histc(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(131310.0469)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(predict).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sigmoid(output).view(-1).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-048bc5b25448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dice' is not defined"
     ]
    }
   ],
   "source": [
    "dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0.5, 1, 0])\n",
    "y = torch.tensor([0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5123927960134477"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_coef(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000024999875001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.zeros((6,1,512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1, 512, 512)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array[0,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 512, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(np_array, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1, 512, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
